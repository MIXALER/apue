# 多线程编程入门之多线程矩阵乘法

一个 2 阶矩阵相乘的例子

![image-20210617195953271](assets/image-20210617195953271.png)

显然，$$c_{11}$$ 通过 [$$a_{11}$$, $$a_{12}$$] 与 $$ [b_{11}, b_{21}]^T $$ 相乘得到，做了两次乘法，一次加法。同理，得到矩阵 C 的其他元素也需要相同数量的乘法和加法。那么，设矩阵的阶数为 n，得到矩阵乘法的时间复杂度为 $$ O(n^3) $$。假如有 $ n^2 $ 个处理器并行工作，那么只需要做 n 次乘法运算即可完成矩阵乘法，时间复杂度降为 O(n)。

现在的计算机都是多核 cpu，每个核都可以看作一个独立的处理器。因此，将计算线程映射到每个核上可以显著提高整个算法的速度。现在的问题是如何用一个独立的线程实现向量相乘，从而实现矩阵乘法的并行运算。事实上，操作系统可以自动地将一个线程放到一个核上去执行，具体怎样实现的就不在本教程的范围内啦。当然，你可以创建数量超过处理器核心数量的线程，然后交给操作系统去安排如何调度执行这些线程。

本教程用 c 语言来实现多线程 $$ n*n $$ 矩阵乘法，并测量其运行性能。从 2*2 矩阵和 4 个线程开始，测量当增加 n 的值，从而增加线程数时，运行时的规模是怎样的。为了避免随机误差，同一个多线程乘法运行多次取平均值。

-   理论上，采用  $ n^2 $ 个线程时，可以达到 O(n) 的性能。但是，实现这一目标的可能性很小。这是为什么呢，下面通过实验来解释背后的原因

-   另一个需要考虑的问题是，性能如何随 n 和用于计算向量积的静态分配线程的数量而变化

-   是否有可能通过重用较小的线程池（小于 $$ n^2 $$）来实现近似相同的性能，其中每个线程执行两个或多个向量乘法的序列，通过实验来解释一下其中的原因。

-   机器的物理核心数量对性能有影响吗，缓存大小呢

在这个实验中，我们只考虑静态线程分配模型，其中在执行矩阵乘法之前创建一个足够大的**线程池**。这个方法比较容易实现。记录的时间只是矩阵乘法的持续时间。不包括创建/销毁线程的时间。解决方案只考虑执行矩阵乘法所花费的时间，而不是线程创建和销毁与操作系统相关的开销。

由于这是多线程编程，根据程序的组织方式，可能会遇到 race hazards，也就是说，一个线程偶尔会在另一个线程之前完成它的工作，结果有时会从不完整的结果中计算出答案。因此需要仔细考虑是否需要使用适当的同步机制。(显然，race hazards 是并发编程中的一个主要问题，也是许多软件灾难的根源!)

用于存储矩阵的数据结构由您决定，但是任何比二维数组更复杂的东西，比如专门的矩阵类，都可能给带来新问题。类似地，通过引用而不是值传递函数参数也是合理的。

本实验不使用 OpenMP 之类的复杂的并发平台。

当然可以用分治的方式实现将矩阵乘法的时间复杂度在单处理器上降低到 $$ O(n^2.81) $$，但是本实验目的是多线程编程，不考虑这种优化方式

本实验不涉及更改操作系统的线程调度方式。依赖操作系统的默认线程调度方式

本实验通过 c 语言实现，并利用 Linux 系统的标准 API

如果能找出决定多线程加速的关键因素，以及所采用的方法/方法的适当性，将会得到分数。

## 1 单个线程执行矩阵乘法的基本情况

```c
#include <stdio.h>
#include <time.h>
#include <stdlib.h>
#include <memory.h>

/*Define the upper bound of the elements in the multi_thread to avoid overflows after multiplication*/
#define RANGE 10
/*The order of the square multi_thread*/
#define N 100
#define REPETITION 1000


int rand_seed = 7;


void gene_matrix(int **matrix, int order)
{
    int i, j;
    for (i = 0; i < order; i++)
    {
        for (j = 0; j < order; j++)
        {
            rand_seed += rand();
            rand_seed = rand_seed % RANGE;
//            *((int *) multi_thread + order * i + j) = rand_seed;
            matrix[i][j] = rand_seed;
        }
    }
}

void print_matrix(const int **matrix, int order)
{
    for (int i = 0; i < order; ++i)
    {
        for (int j = 0; j < order; ++j)
        {
            int tmp = matrix[i][j];
            printf("%d ", tmp);
        }
        printf("\n");
    }
}

int **malloc_matrix(int n)
{
    int **A = (int **) malloc(sizeof(int *) * n);
    for (int i = 0; i < n; i++)
        A[i] = (int *) malloc(sizeof(int) * n);


    for (int i = 0; i < n; ++i)
    {
        for (int j = 0; j < n; ++j)
        {
            A[i][j] = 0;
        }
    }

    return A;
}

void free_matrix(int **matrix, int n)
{
    for (int i = 0; i < n; i++)
        free(matrix[i]);
    free(matrix);
}

void to_zero(int **res, int n)
{
    for (int i = 0; i < n; ++i)
    {
        for (int j = 0; j < n; ++j)
        {
            res[i][j] = 0;
        }
    }
}

int main()
{
    setbuf(stdout, NULL);
    for (int order = 2; order <= N; ++order)
    {
        int **matrixA = malloc_matrix(order);
        int **matrixB = malloc_matrix(order);
        int **res = malloc_matrix(order);
        double total_time = 0;
        for (int time_i = 0; time_i < REPETITION; ++time_i)
        {
            gene_matrix((int **) matrixA, order);
            gene_matrix((int **) matrixB, order);
            to_zero(res, order);
            clock_t start = clock();
            for (int i = 0; i < order; i++)
                for (int j = 0; j < order; j++)
                    for (int k = 0; k < order; k++)
                        res[i][j] += matrixA[i][k] * matrixB[k][j];
            clock_t finish = clock();
            total_time += (double) (finish - start);
        }
        free_matrix(matrixA, order);
        free_matrix(matrixB, order);
        free_matrix(res, order);
        printf("multi_thread order is: %d, cycle times : %d\n", order, REPETITION);
        printf("average time of serial calculation is %.10f sec\n",
               (double) (total_time / REPETITION) / CLOCKS_PER_SEC);
    }
    return 0;
}
```

单个线程执行矩阵乘法是通过一个三重循环来实现的。因为 cpu 计算不同大小的数字相乘所用的时间不同，所以实验中利用随机函数生成随机矩阵来保证实验能够模拟自然情况下的矩阵乘法。然后通过时间函数记录每个三重循环所用的时间，重复多次取平均值，来准确的获得每次执行矩阵乘法所需要的时间。为了便于同后续的多线程矩阵乘法做性能比较，本实验获取了矩阵阶数从 2 到 100 中每个矩阵阶数做乘法所需要的时间。

## 2 矩阵乘法的多线程加速

由上面的单线程矩阵乘法知道，每次矩阵乘法计算过程包含一个三重循环过程，这将带来 O(n3) 的时间复杂度。考虑到矩阵乘法是一个重复操作过程，即将矩阵 A 的不同行与矩阵 B 的不同列相乘，且各个相乘结果之间不存在互相依赖关系，容易想到利用多线程计算来对矩阵乘法的计算过程进行加速。那么，如果用一个线程实现矩阵的一行乘以另一个矩阵的一列，那么 N 阶矩阵相乘需要 N*N 个线程才能完成任务。通常的多线程实现过程利用了 Linux 系统的标准库 pthread.h ，通过创建线程实现并将具体的任务传入线程来完成一个具体的任务。下面演示通过这种方式实现的多线程矩阵乘法。

```c
#include <stdio.h>
#include <pthread.h>
#include <time.h>
#include <stdlib.h>
#include <memory.h>

/*Define the upper bound of the elements in the multi_thread to avoid overflows after multiplication*/
#define RANGE 10
/*The order of the square multi_thread*/
#define N 100
#define REPETITION 1000

struct multi_matrix
{
    int **matrixA;
    int **matrixB;
    int **res;
};


struct param
{
    struct multi_matrix *p_matrix;
    int row;
    int col;
    int order;
};

int rand_seed = 7;


void ThreadProc(struct param *tmp);

void gene_matrix(int **matrix, int order);

void print_matrix(const int **matrix, int order);

int **malloc_matrix(int n);

pthread_t **malloc_pthread(int n);

void free_matrix(int **matrix, int n);

void to_zero(int **res, int n);

void free_thread(pthread_t **hthread, int n);

struct param **malloc_struct_param(int n);

void free_param(struct param **pass, int n);


int main()
{
    setbuf(stdout, NULL);
    for (int order = 2; order <= N; ++order)
    {
        pthread_t **hThread = malloc_pthread(order);
        struct multi_matrix tmp_multi_matrix;
        tmp_multi_matrix.matrixA = malloc_matrix(order);
        tmp_multi_matrix.matrixB = malloc_matrix(order);
        tmp_multi_matrix.res = malloc_matrix(order);
        struct param **pass = malloc_struct_param(order);
        double total_time = 0;
        for (int time_i = 0; time_i < REPETITION; ++time_i)
        {
            gene_matrix(tmp_multi_matrix.matrixA, order);
            gene_matrix(tmp_multi_matrix.matrixB, order);
            to_zero(tmp_multi_matrix.res, order);
            clock_t start = clock();
            for (int i = 0; i < order; i++)
            {
                for (int j = 0; j < order; ++j)
                {
                    pass[i][j].row = i;
                    pass[i][j].col = j;
                    pass[i][j].order = order;
                    pass[i][j].p_matrix = &tmp_multi_matrix;
                    pthread_create(&hThread[i][j], NULL, (void *) ThreadProc, &pass[i][j]);
                }
            }
            for (int i = 0; i < order; ++i)
            {
                for (int j = 0; j < order; ++j)
                {
                    pthread_join(hThread[i][j], NULL);
                }
            }
            clock_t finish = clock();
            total_time += (double) (finish - start);
        }
        free_matrix(tmp_multi_matrix.matrixA, order);
        free_matrix(tmp_multi_matrix.matrixB, order);
        free_matrix(tmp_multi_matrix.res, order);
        free_param(pass, order);
        free_thread(hThread, order);
        printf("multi_thread order is: %d, cycle times : %d, num of threads : %d\n", order, REPETITION, order * order);
        printf("average time of parallel computing is %.10f sec\n",
               (double) (total_time / REPETITION) / CLOCKS_PER_SEC);
    }
    return 0;
}

void ThreadProc(struct param *tmp)
{
    int row = tmp->row;
    int col = tmp->col;
//    printf("row: %d col: %d \n", row, col);
    int rs = 0;

    int loop;
    for (loop = 0; loop < tmp->order; ++loop)
    {
        rs += tmp->p_matrix->matrixA[row][loop] * tmp->p_matrix->matrixB[loop][col];
    }
//    printf("rs:  %d \n", rs);
    tmp->p_matrix->res[row][col] = rs;
}

void gene_matrix(int **matrix, int order)
{
    int i, j;
    for (i = 0; i < order; i++)
    {
        for (j = 0; j < order; j++)
        {
            rand_seed += rand();
            rand_seed = rand_seed % RANGE;
//            *((int *) multi_thread + order * i + j) = rand_seed;
            matrix[i][j] = rand_seed;
        }
    }
}

void print_matrix(const int **matrix, int order)
{
    for (int i = 0; i < order; ++i)
    {
        for (int j = 0; j < order; ++j)
        {
            int tmp = matrix[i][j];
            printf("%d ", tmp);
        }
        printf("\n");
    }
}

int **malloc_matrix(int n)
{
    int **A = (int **) malloc(sizeof(int *) * n);
    for (int i = 0; i < n; i++)
        A[i] = (int *) malloc(sizeof(int) * n);


    for (int i = 0; i < n; ++i)
    {
        for (int j = 0; j < n; ++j)
        {
            A[i][j] = 0;
        }
    }

    return A;
}

pthread_t **malloc_pthread(int n)
{
    pthread_t **A = (pthread_t **) malloc(sizeof(pthread_t * ) * n);
    for (int i = 0; i < n; i++)
        A[i] = (pthread_t *) malloc(sizeof(pthread_t) * n);

    return A;
}


struct param **malloc_struct_param(int n)
{
    struct param **A = (struct param **) malloc(sizeof(struct param *) * n);
    for (int i = 0; i < n; i++)
        A[i] = (struct param *) malloc(sizeof(struct param) * n);

    return A;
}

void free_matrix(int **matrix, int n)
{
    for (int i = 0; i < n; i++)
        free(matrix[i]);
    free(matrix);
}

void free_thread(pthread_t **hthread, int n)
{
    for (int i = 0; i < n; i++)
        free(hthread[i]);
    free(hthread);
}

void free_param(struct param **pass, int n)
{
    for (int i = 0; i < n; i++)
        free(pass[i]);
    free(pass);
}

void to_zero(int **res, int n)
{
    for (int i = 0; i < n; ++i)
    {
        for (int j = 0; j < n; ++j)
        {
            res[i][j] = 0;
        }
    }
}
```

理论上讲，用 N* N 个线程来执行矩阵乘法的时间复杂度应该降低到 O(N)，但是运行结果显示多线程执行矩阵乘法所用时间远超单线程执行矩阵乘法所用时间。导致这样的结果的原因有两个。第一个是计算用时的时候，不可避免地要将创建线程的时间计统计在内，而创建线程的耗时相比于简单的进行一行乘以一列的乘加运算，无疑是耗时高得多的。第二个原因是当矩阵阶数增加时，所需要的线程数量将是矩阵阶数平方倍的增加，所以会产生大量的线程。而每个线程都需要操作系统来调度执行，因为线程数量已经远远超过 cpu 核心的数量。所以需要操作系统来安排该由 cpu 的哪个核心执行哪个线程，并且线程需要排队等待 cpu 的调度。当线程数量远大于 cpu 核心数量的时候，调度花费的时间就远远高于执行矩阵行列的乘加运算的用时了。





导致多线程执行速度比单线程运行慢的原因有两个。

第一个原因是在线程创建和销毁过程钟消耗了大量的时间。即pthread_create, pthread_join函数所花费的时间。创建进程本身的时间比任务本身，即矩阵的一行乘以矩阵的一列所花费的时间要多。第二个原因是该方法实现的多线程矩阵乘法的线程数量是矩阵阶数的两倍。当矩阵阶数变大时，线程数量就会变得很大，远远超过了cpu的核心数。操作系统会用内部的调度算法来对这些线程进行调度。调度过程会消耗大量的时间。

考虑到上述问题，一个改进办法是使用线程池来实现多线程矩阵乘法，即创建一定数量的线程作为线程池，这批线程在矩阵乘法的整个执行过程都将存在，不会消失。然后线程池中线程数量大概大约等于处理器核心数量。这样理论上就能实现每个cpu核心运行一个线程，然后将所有的子任务（矩阵的一行乘以矩阵的一列）分配给线程池里面的线程去执行。但是这种情况下会出现线程同步问题。。也就是说，线程池是一个生产者消费者模型。即将每个任务加入线程池时，都是对线程池这个临界资源的访问。这里对临界资源的访问是一个原子操作，会导致耗时增加。（如果不能执行完一整个操作，就会阻塞等待唤醒）

因此线程池只能是比多线程方式快，但是依然不如单线程的方式快。

因为 cpu 是通用处理器，对矩阵乘法这类简单的并行计算任务不太擅长。除此之外，直接使用操作系统提供的同步和调度算法来实现矩阵乘法这种简单的任务调度和同步就会显得很笨重。更好的实现方式是 SIMD 单指令多数据流的方式，具体的实现方式还需要研究。。。

除开上面的解答，你自己需要补充的内容：

1.  介绍上面上个算法的具体实现。
2.  pthread_create, pthread_join函数的原理
3.  线程池的原理，线程同步的原理，生产者消费者模型如何应用于该矩阵乘法的实现过程，以及同步为啥会导致耗时增加。

## 3 将矩阵乘法分布在少于 N*N个线程上的实现和演示

考虑到上面提到的过多的线程来执行矩阵乘法的缺点，同时也要利用 cpu 多核心并行运算的优点。自然而然地就想到，不建立过多的线程，从而避免线程调度耗费的时间。所以将核心数量控制在cpu 核心数量相同的数量级。那么，就出现了一个问题，如何将矩阵乘法的任务平均分配给这些线程呢。例如一个100阶的矩阵相乘，就需要 100 * 100 次的行列相乘。将其分配到8个线程上（因为我的 Linux 系统运行在一个 8 核心的 cpu 上）。也就是每个线程执行 1250 次行列乘加运算。那么该如何分配具体的行列相乘并相加的任务到具体的线程呢？8个线程的执行100阶矩阵乘法时可以确保每个线程分到的任务数量是相等的。那么 99 阶矩阵乘法需要的行列乘加运算次数为 99 * 99 次，8 个线程执行会导致有个线程少执行若干个行列乘加运算。当线程数量不固定，矩阵大小不固定的时候，这样的方式会给代码编写带来很大的困难。这时，一个简单的想法是，我创建一定数量的线程，并固定在那里，形成一个队列，然后把矩阵乘法看作一定数量的子任务的集合，显然每个子任务就是一个行列相乘并相加。然后我就把这些子任务分配给线程执行，线程执行完了之后也不销毁，等待下一个任务的到来，直到所有的任务执行完毕后再销毁。这就是线程池的概念。下面就是通过线程池实现矩阵乘法的展示：

```c++
#include <stdio.h>
#include <stdlib.h>
#include "thread_pool.h"

/*Define the upper bound of the elements in the multi_thread to avoid overflows after multiplication*/
#define RANGE 10
/*The order of the square multi_thread*/
#define N 100
#define REPETITION 1000
int N_THREADS = 32;
int rand_seed = 7;

struct multi_matrix
{
    int **matrixA;
    int **matrixB;
    int **res;
};

struct param
{
    struct multi_matrix *p_matrix;
    int row;
    int col;
    int order;
};


void ThreadProc(struct param *tmp);

void gene_matrix(int **matrix, int order);

void print_matrix(const int **matrix, int order);

int **malloc_matrix(int n);

void free_matrix(int **matrix, int n);

void to_zero(int **res, int n);

struct param **malloc_struct_param(int n);

void free_param(struct param **pass, int n);


int main()
{
    setbuf(stdout, NULL);
    for (int order = 100; order <= N; ++order)
    {
        for (int n_thread = 1; n_thread <= N_THREADS && n_thread <= order * order; n_thread++)
        {
            threadpool_t pool;
            threadpool_init(&pool, n_thread);
            struct multi_matrix tmp_multi_matrix;
            tmp_multi_matrix.matrixA = malloc_matrix(order);
            tmp_multi_matrix.matrixB = malloc_matrix(order);
            tmp_multi_matrix.res = malloc_matrix(order);
            struct param **pass = malloc_struct_param(order);
            double total_time = 0;
            for (int time_i = 0; time_i < REPETITION; ++time_i)
            {
                gene_matrix(tmp_multi_matrix.matrixA, order);
                gene_matrix(tmp_multi_matrix.matrixB, order);
                to_zero(tmp_multi_matrix.res, order);
                clock_t start = clock();
                for (int i = 0; i < order; i++)
                {
                    for (int j = 0; j < order; ++j)
                    {
                        pass[i][j].row = i;
                        pass[i][j].col = j;
                        pass[i][j].order = order;
                        pass[i][j].p_matrix = &tmp_multi_matrix;
                        threadpool_add_task(&pool, (void *) ThreadProc, &pass[i][j]);
                    }
                }
                clock_t finish = clock();
                total_time += (double) (finish - start);
            }
            threadpool_destory(&pool);
            free_matrix(tmp_multi_matrix.matrixA, order);
            free_matrix(tmp_multi_matrix.matrixB, order);
            free_matrix(tmp_multi_matrix.res, order);
            free_param(pass, order);
            printf("multi_thread order is: %d, cycle times : %d, num of threads in thread pool is : %d\n", order, REPETITION,
                   n_thread);
            printf("average time of parallel computing based on thread pool is %.10f sec\n",
                   (double) (total_time / REPETITION) / CLOCKS_PER_SEC);
        }
    }
    return 0;
}


void ThreadProc(struct param *tmp)
{
    int row = tmp->row;
    int col = tmp->col;
//    printf("row: %d col: %d \n", row, col);
    int rs = 0;

    int loop;
    for (loop = 0; loop < tmp->order; ++loop)
    {
        rs += tmp->p_matrix->matrixA[row][loop] * tmp->p_matrix->matrixB[loop][col];
    }
//    printf("rs:  %d \n", rs);
    tmp->p_matrix->res[row][col] = rs;
}

void gene_matrix(int **matrix, int order)
{
    int i, j;
    for (i = 0; i < order; i++)
    {
        for (j = 0; j < order; j++)
        {
            rand_seed += rand();
            rand_seed = rand_seed % RANGE;
//            *((int *) multi_thread + order * i + j) = rand_seed;
            matrix[i][j] = rand_seed;
        }
    }
}

void print_matrix(const int **matrix, int order)
{
    for (int i = 0; i < order; ++i)
    {
        for (int j = 0; j < order; ++j)
        {
            int tmp = matrix[i][j];
            printf("%d ", tmp);
        }
        printf("\n");
    }
}

int **malloc_matrix(int n)
{
    int **A = (int **) malloc(sizeof(int *) * n);
    for (int i = 0; i < n; i++)
        A[i] = (int *) malloc(sizeof(int) * n);


    for (int i = 0; i < n; ++i)
    {
        for (int j = 0; j < n; ++j)
        {
            A[i][j] = 0;
        }
    }

    return A;
}


struct param **malloc_struct_param(int n)
{
    struct param **A = (struct param **) malloc(sizeof(struct param *) * n);
    for (int i = 0; i < n; i++)
        A[i] = (struct param *) malloc(sizeof(struct param) * n);

    return A;
}

void free_matrix(int **matrix, int n)
{
    for (int i = 0; i < n; i++)
        free(matrix[i]);
    free(matrix);
}

void free_param(struct param **pass, int n)
{
    for (int i = 0; i < n; i++)
        free(pass[i]);
    free(pass);
}

void to_zero(int **res, int n)
{
    for (int i = 0; i < n; ++i)
    {
        for (int j = 0; j < n; ++j)
        {
            res[i][j] = 0;
        }
    }
}
```

下面是实现线程池的头文件

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <errno.h>
#include <time.h>
#include <pthread.h>

typedef struct condition
{
    pthread_mutex_t pmutex;
    pthread_cond_t pcond;
} condition_t;

typedef struct task
{
    void *(*run)(void *arg);

    void *arg;
    struct task *next;
} task_t;

typedef struct threadpool
{
    condition_t ready;
    task_t *first;
    task_t *last;
    int counter;
    int idle;
    int max_threads;
    int quit;
} threadpool_t;


int condition_init(condition_t *cond)
{
    int status;
    if ((status = pthread_mutex_init(&cond->pmutex, NULL)))//返回0代表初始化成功
        return status;
    if ((status = pthread_cond_init(&cond->pcond, NULL)))
        return status;
    return 0;
}

int condition_lock(condition_t *cond)
{
    return pthread_mutex_lock(&cond->pmutex);
}

int condition_unlock(condition_t *cond)
{
    return pthread_mutex_unlock(&cond->pmutex);
}

int condition_wait(condition_t *cond)
{
    return pthread_cond_wait(&cond->pcond, &cond->pmutex);
}

int condition_timewait(condition_t *cond, const struct timespec *abstime)
{
    return pthread_cond_timedwait(&cond->pcond, &cond->pmutex, abstime);
}

int condition_signal(condition_t *cond)
{
    return pthread_cond_signal(&cond->pcond);
}

int condition_broadcast(condition_t *cond)
{
    return pthread_cond_broadcast(&cond->pcond);
}

int condition_destory(condition_t *cond)
{
    int status;
    if ((status = pthread_mutex_destroy(&cond->pmutex)))
        return status;
    if ((status = pthread_cond_destroy(&cond->pcond)))
        return status;
    return 0;
}


void *thread_routine(void *arg)
{
    struct timespec abstime;
    int timeout;
//    printf("thread 0x%0x is starting\n", (int) pthread_self());
    threadpool_t *pool = (threadpool_t *) arg;
    while (1)
    {
        timeout = 0;
        condition_lock(&pool->ready);
        pool->idle++;
        //Wait for the queue to be notified of the arrival of a task or thread pool destruction
        while (pool->first == NULL && !pool->quit)
        {
//            printf("thread 0x%0x is waiting\n", (int) pthread_self());
            clock_gettime(CLOCK_REALTIME, &abstime);
            abstime.tv_sec += 2;
            int status = condition_timewait(&pool->ready, &abstime);
            if (status == ETIMEDOUT)
            {
//                printf("thread 0x%0x is wait timed out\n", (int) pthread_self());
                timeout = 1;
                break;
            }

        }
        pool->idle--;

        if (pool->first != NULL)
        {
            task_t *t = pool->first;
            pool->first = t->next;
            //It needs to be unlocked in order to add new tasks.Other consumer threads can enter the wait task.
            condition_unlock(&pool->ready);
            t->run(t->arg);
            free(t);
            condition_lock(&pool->ready);
        }
        if (pool->quit && pool->first == NULL)
        {
            pool->counter--;
            if (pool->counter == 0)
            {
                condition_signal(&pool->ready);
            }
            condition_unlock(&pool->ready);
            break;
        }

        if (timeout && pool->first == NULL)
        {
            pool->counter--;
            condition_unlock(&pool->ready);
            break;
        }
        condition_unlock(&pool->ready);
    }

//    printf("thread 0x%0x is exiting\n", (int) pthread_self());
    return NULL;
}

void threadpool_init(threadpool_t *pool, int threads)
{
    condition_init(&pool->ready);
    pool->first = NULL;
    pool->last = NULL;
    pool->counter = 0;
    pool->idle = 0;
    pool->max_threads = threads;
    pool->quit = 0;
}

void threadpool_add_task(threadpool_t *pool, void *(*run)(void *arg), void *arg)
{
    task_t *newstask = (task_t *) malloc(sizeof(task_t));
    newstask->run = run;
    newstask->arg = arg;
    newstask->next = NULL;

    condition_lock(&pool->ready);
    if (pool->first == NULL)
    {
        pool->first = newstask;
    } else
        pool->last->next = newstask;
    pool->last = newstask;
    if (pool->idle > 0)
    {
        condition_signal(&pool->ready);
    } else if (pool->counter < pool->max_threads)
    {
        pthread_t tid;
        pthread_create(&tid, NULL, thread_routine, pool);
        pool->counter++;
    }
    condition_unlock(&pool->ready);
}

void threadpool_destory(threadpool_t *pool)
{

    if (pool->quit)
    {
        return;
    }
    condition_lock(&pool->ready);
    pool->quit = 1;
    if (pool->counter > 0)
    {
        if (pool->idle > 0)
            condition_broadcast(&pool->ready);

        while (pool->counter > 0)
        {
            condition_wait(&pool->ready);
        }
    }
    condition_unlock(&pool->ready);
    condition_destory(&pool->ready);
}
```

相比于上一种方法实现的多线程矩阵乘法，基于线程池实现的矩阵乘法运行速度大幅提升，但是依然比单线程实现的矩阵乘法速度慢。主要原因有两点，第一点是，线程池一次创建可以重复多次使用，省去了大量的线程创建和线程销毁的时间，每次只需要将任务放入线程池中即可。第二点原因是线程池中的线程数量更少，用于进程调度所花费的时间更少。但仍然比单线程矩阵乘法执行速度慢的原因是线程池运算过程中的大量同步操作花费了大量的时间。

## 4 基于处理器特性的整体分析

本实验平台为 Linux，cpu 核心数量为8 。因此理论上8线程的矩阵乘法是能达到最好性能。但是本实验的实验结果没能验证这一点。我觉得原因在于矩阵乘法的任务本身和实现矩阵乘法的系统有关。首先是矩阵乘法的任务本身，本次实验由于时间原因只是进行到了100阶的矩阵乘法，cpu是一个高速设备，执行100个数的相乘并相加是非常快速的。消耗的时间远远低于进程调度和创建销毁进程所消耗的时间。如果是更高阶的矩阵乘法的话，那么每次行列乘加的任务就会变得很大，那么任务本身的耗时就会超过线程创建，线程调度的耗时。在这种情况下多线程执行矩阵乘法就变得更有意义。除开 cpu 的因素外，本次实验所基于的操作系统也是一个重要的因素。我们使用的是操作系统提供的线程创建和调度的方法，通常来讲，操作系统提供的线程调度和创建销毁方式是具体很强的通用性的。矩阵乘法这种级别的任务显得有点过于简单和单一。如果直接用操作系统提供的线程操作则显得过于笨重。（这一段为个人直觉，未经实验）

## 5 最总结论

矩阵乘法在理论上可以用多线程的方式实现 N * N 倍的加速，但是现实情况下很难实现，而且依赖于具体的硬件平台和软件算法。

阶数较低的矩阵乘法非常不适合于并行计算，用单线程计算要快得多，因为 cpu 本身的计算速度非常快。

阶数较高的矩阵通过多线程加速的方式可以取得相比于单线程更好的性能，但是矩阵的本身要足够大，且使用的线程数量要小于等于 cpu 核心数量。

矩阵乘法虽然是一个简单的任务，但是具有非常重要的作用。多线程优化加速矩阵乘法是一个非常值得探讨和研究的课题。事实上，现在应用非常广发的计算机视觉任务就非常依赖于多线程矩阵乘法的实现。但是这项任务用到了一个不同于 cpu 的硬件，那就是 GPU。GPU不具备cpu那样好的通用编程性能，但是它拥有数量远超过 cpu的核心数量可以用于快速的实现矩阵乘法。同时其在线程调度和算法层面做了大量的优化，具体的优化方法有待后续学习。

参考资料：

https://www.cnblogs.com/s-lisheng/p/11244873.html

https://www.cnblogs.com/zhangchaoyang/articles/1853822.html

https://blog.csdn.net/weixin_42819452/article/details/102807147

https://github.com/micwu/ThreadPool
